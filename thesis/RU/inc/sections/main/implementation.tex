\section{Проектирование и реализация системы прогнозирования}
\subsection{Cтруктура разрабатываемой системы}
\subsubsection{Определение потока данных разрабатываемой системы}
Для определения структуры разрабатываемой автоматизированной системы, реализующей алгоритм прогнозирования взаимодействий
пользователей с рекламными элементами интернет-страниц для начала определим диаграмму потока данных, используемых при
построении прогноза.

Диаграмма потока данных (англ. Data Flow Diagram, DFD) -- методология представления потока данных, используемых или
пораждаемых в процессе или системе. Такой способ визуализации был следствием развития одного из класса UML диаграм
диаграмм деятельности (англ. Activity Diagram)~\autocite{impl:ad}. В 70-ые годы прошлого столетия данная методология
приобрела большую популярность благодаря работе~\autocite{impl:dfd} коллектива под руководством Эдварда Йордана и
Ларри Константина.

Главное достоинство данного вида представления заключается в легком способе построения высокоуровневой абстракции
потока данных в разрабатываемой системе. Один из вариантов диаграммы потока данных является нотация 
Йордана~\autocite{impl:yourdan}, для которой определены следующие компоненты:
\begin{enumerate}
    \item процесс (функция, трансформация) требуется для представления каким образом система обрабатывает 
    входные данные, на диаграмме изображается в виде круга с текстом, кратко описывающем детали обработки;
    \item хранилище определяет коллекцию данных в состоянии покоя (отсутствия процесса обработки над данными),
    на диаграмме изображается двумя параллельными отрезками и текстом, кратко характеризующим тип хранилища и
    коллекцию данных; 
    \item терминаторы представляют собой внешние объекты, с которыми взаимодействует система, графически представлены
    в виде прямоугольника;
    \item поток визуализирует порядок перехода данных от одного процесса или хранилища к другому процессу или
    хранилищу, на диаграмме изображается при помощи однонаправленной стрелки.
\end{enumerate}

При построении начального приближения диаграммы потока данных разрабатываемой системы прогнозирования взаимодействий
пользователей с рекламными элементами интернет-страниц воспользуемся блок схемой алгоритма на 
рисунке~\ref{img:algo-flowchart}.

Входными данными, использумыми в процессе работы разрабатываемой системы, является протокол работы рекламной системы.
Процессами для обработки данных будут являться процессы простроения вероятностной выборки и статистики метрик,
прогноза метрик и протокола работы и калибровочный процесс. В качестве хранилища должна выступать файловая система
вычислительной машины, на которой запущена система. Высокоуровневая диаграмма потока данных разрабатываемого приложения
представлена на рисунке ~\ref{img:dataflowchartinit}.
\input{inc/images/dataflowchartinit}

\subsubsection{Диаграмма классов разрабатываемой системы}
В соответствиии с диаграммой потока данных, изображенной на рисунке~\ref{img:dataflowchartinit} представим поток обработки
в виде следуюших стадий:
\begin{enumerate}
    \item предварительная обработка исходного протокола с целью приведения к виду, приемлимому для дальнейшего использования;
    \item проведение вероятностной выборки взаимодействий из предобработанного протокола работы;
    \item построение статистики метрик количества взаимодействий и количества уникальных пользователей на основе данных
    из предобработанного протокола работы;
    \item построение прогноза протокола работы рекламной системы на основе выборки и статистики;
    \item построение прогнозов метрик количества взаимодействий и количества уникальных пользователей на основе собранной
    статистики;
    \item проведение калибровочного процесса;
    \item построение итогового прогноза протокола работы рекламной системы.
\end{enumerate}

Для реализации данных стадий разработан набор классов, каждый из которых обеспечивает необходимую функциональность и
возможность параметризации. Для доступа к хранилищу реализован класс, обеспечивающий функциональность чтения--записи
исходных и порождаемых в процессе работы системы данных. Для визуализации описания классов, их атрибутов и 
методов используется диаграмма классов (англ. Static Structure Diagram),

Диаграмма классов -- структурная диаграмма языка моделирования UML, предназначенная для демонстрации иерархии классов,
их композиций и отношений, членов класса (атрибутов и методов)~\autocite{impl:ad}. Каждый элемент диаграммы классов представляет собой
ячейку, содержащую три компоненты:
\begin{enumerate}
    \item имя класса, пишется жирным шрифтом по центру ячейки (в случае если класс абстрактный, начертание должно быть жирным
    и курсивным);
    \item атрибуты класса, выравненивание по левому краю;
    \item методы класса, выравненивание по левому краю.
\end{enumerate}

В случае данной работы, в качестве классов для реализации функциональности стадий используются 6 классов стадий, каждый
из которых имеет публичный метод \texttt{run}, выполнящий запуск стадии и обработку данных, детали которой определяются
конкретной имплементацией метода. Стадии имеют доступ к хранилищу данных благодаря полю \texttt{provider}. Параметризация
стадий достигается путем введение специлизированных полей в классы, так для стадии калибровки класс \texttt{CalibrationStage}
включает поля границ решения СЛАУ \texttt{left\_border} и \texttt{right\_border} и точность решения \texttt{tolerance}. Класс
\texttt{DataProvider} реализует функциональность чтения-записи данных. 

Диаграмма классов, используемых при реализации системы изображена
на рисунке~\eqref{img:uml}.
\input{inc/images/uml}

\subsection{Выбор и обоснование комплекса программных средств}
\subsubsection{Язык программирования Python}

В качестве языка программирования, используемого для программной реализации алгоритма прогнозирования взаимодействий пользователей
с рекламными элементами интернет-страниц, используется язык программирования Python. Язык разработан в начале 90-ых годов
XX века нидерландским инженером Гвидо ван Россумом и до сих пор активно развивается (актуальная мажорная версия на апрель 
2019 года 3.7). Выбор языка Python обсуловлен следующими факторами:
\begin{enumerate}
    \item язык программирования Python поддерживает множество парадигм программирования (функциональное, объектно-ориентированное,
    императивное и т.д.);
    \item синтаксис и лексика языка программирования Python минималастична, следование стандарту языка программирования 
    (англ. Python Enhancement Proposals, PEP)~\autocite{impl:pep} позволяет писать легко читаемый код и повышает 
    производительность разработчика;
    \item Python занимает 4 место в рейтинге языков программирования TIOBE~\autocite{impl:rating}, отражающем популярность 
    языка программирования среди разработчиков;
    \item для языка программирования Python реализовано огромное число свободно распространяемых библиотек различной 
    направленности (машинное обучение, анализ и обработка данных, реализация методов вычислетельной математики и 
    т.д.)~\autocite{impl:awesome-python}.
\end{enumerate}

\subsubsection{Система распределенной работы с данными Apache Spark}

Данные, получаемые непосредственно от рекламной системы, представляют собой набор файлов, описывающих протокол работы
рекламной системы за определенный период времени. Размер данного файла определяется структурой протокола работы релкамной системы,
типами данных, представленных в структуре и форматом хранения файла. Из-за разнообразия видов рекламных систем, система для обработки
таких данных должна являться универсальным средством, способным  загружать различные типы входной информации, обрабатывать и агрегировать
 различные структуры даных.

Подход к обработке данных, при котором данные проходят цикл загрузки, обработки и агрегации называется принцип ETL 
(англ. extract-transform-load). В качестве библиотеки, реализующей принцип ETL используется свободно распространяемая
система обработки разнородных и слабоструктурированных данных Apache Spark, разработанная канадско-румынским специалистом
Матеем Захария~\autocite{impl:spark}.

Apache Spark представляет собой универсальных вычислительный механизм и набор библиотек, предназначенных для параллельной
обработки данных на распределенных вычислительных системах (кластерах) при помощи языков Scala, Java, R и 
Python~\autocite{impl:spark-overview}. Для последнего Apache Spark имеет необходимый интерфейс взаимодействия (англ. API) 
PySpark. Для разворачивания приложений, использующих Apache Spark может использоваться как локальная машина (например, 
для тестирования), да и среда оркестрации ресурсов (для конечных решений).

Для отслеживания работы программы, использующей Apache Spark, реализован интерфейс визуализации  Apache Spark UI, пользовательский
интерфейс которого представлен на рисунке ~\ref{img:spark}.
\input{inc/images/spark}
Apache Spark UI явлется сервисом, существующим все время жизни родительского приложения, в котором можно отследить количество операций,
объем обрабатываемых данных, количество выделяемых ресурсов и прочие параметры, небходимые для диагностики работы приложения.

При разработке приложения, используещего Apache Spark, необходимо учитывать ряд особеностей:
\begin{enumerate}
    \item приложение, используещее Apache Spark, состоит из ведущего процесса (англ. driver) и набора процессов 
    вычислителей (англ. executors), ведущий процесс является неотъемлимой часть системы, использующей Apache Spark,
    и служит для поддержки работоспособности системы на всех сроке ее жизни, процессы вычислителей выполняют
    назначенную драйвером работу и отчитываются о процессе выполнения этих задач;
    \item данные представлены при помощи набора высокоуровневых абстракций, таких как таблица данных (англ. DataFrame),
    типизированная коллекция данных (англ. Dataset), SQL-таблица (англ. SQL TABLE),  представляющий собой различные
    преставления распределенных низкоуровневых коллекций данных (англ. RDD, Resilient Distributed Dataset);
    \item обработка операций обеспечивается при помощи базовых трансформаций преобразования (англ. map), фильтрации (англ. filter), 
    сокращения (англ. reduce), различия (англ. distinct), доступных благодаря высокоуровнему API Apache Spark, так же доступны
    операции группировки (англ. groupBy), сливания (англ. merge);
    \item для обеспечения параллельной обработки данных Apache Spark использует принцип партиционирования (англ. Partitioning),
    при котором исходные данные разбиваются на набор мелких частей, называемых партициями~\autocite{impl:partioning};
    \item при выполнении пользовательского кода, Apache Spark стоит граф выполнения, состоящего из двух структур: логического 
    плана (состоит из абстрактных операций преобразования) и физического плана (определяет каким образом задачи логического 
    плана будут выполнены исполнителями);
    \item приложение работает на основе принципа ленивого исполнения~\autocite{impl:spark-guide}, при котором вместо немедленной обработки данных,
    выполняемые операции анализируются и Apache Spark оптимизирует порядок их выполнения. 
\end{enumerate}

\subsubsection{Распределенное хранилище данных Apache Hadoop}
В качестве хранилища данных, изображенных на диаграмме ~\ref{img:dataflowchartinit} используется система
Apache Hadoop. Apache Hadoop разработан До Каттингом в начале 2000-ых и анансирован в 2006 году~\autocite{impl:hadoop}
как независимое средство распределенного хранения и обработки данных с использованием алгоритма MapReduce~\autocite{impl:mapreduce}.

Выбор Apache Hadoop обоснован следующими факторами:
\begin{enumerate}
    \item высокая степень интеграции Apache Spark с экосистемой Apache Hadoop (вплоть до
    возможности запуска в одной системе оркестрирования ресурсов);
    \item широкое распространение и высокая степень документированности процесса
    разворачивания Hadoop хранилища;
    \item независимость от типа хранимых данных и их структуры (в качестве формата данных
    предпочтительно использовать один из форматов экосистемы Hadoop Apache Avro~\autocite{impl:avro} 
    или Apache Parquet~\autocite{impl:parquet}).
\end{enumerate}

Структурно распределенная файловая система Hadoop  (англ. Hadoop Distributed File System) представляет
собой следующий набор узлов двух типов~\autocite{impl:hadoop-architecture}, запущенных на вычислительном кластере
и управляющих работой распределенной системы хранения данных:
\begin{enumerate}
    \item узла имени (англ. namenode), управлющей пространством имен файловой системы, поддерживает порядок
    дерева файлов и директорий, распределяет файлы, хранимые в файловой системе, по узлам данных;
    \item узлов данных (англ. datanode), которые непосредственно хранят данные в виде блоков и информируют
    узел имен о списке файлов.
\end{enumerate}

Для интерфейса управленяи распределенной файловой системой Hadoop используется интерфейс командной строки
\texttt{hdfs-cli} или система доступа к хранилищу данных Hadoop WebHDFS, изображенный на рисунке \ref{img:hadoop}.
\input{inc/images/hadoop}

\subsubsection{Система оркестрирования ресурсов Apache Mesos}
Для управления ресурсами вычислительной системы, используемой для работы алгоритма 
прогнозирования взаимодействий пользователей с рекламными элементами интернет-страниц
используется система Apache Mesos. Система Apache Mesos разработана в начале 2000-ых в институте
Беркли командой под руководством Бенджамина Хиндмана и Матея Захария~\autocite{impl:mesos-article}.

Основное назначение данной системы это автоматизация управления ресурсами вычислительной система, оптимизации
утилизации используемых ресурсов, предоставление высокоуровневого интерфейса взаимодействия между клиентским
приложением и процессом выделения ресурсов. Основной принцип, который используется Apache Mesos для выделения ресурсов и выполнения задач, это принцип
гранулярного деления, основого списка задач на подзадачи.

Для мониторинга и отслеживания работы системы Apache Mesos, используется интерфейс Mesos UI,
на котором можно отследить статус, количество выделенных ресурсов и прогресс выполения приложений.
Вид интерфейса Mesos UI представлен на рисунке \ref{img:mesos}.
\input{inc/images/mesos}

Структурно, любая система, запущенная в системе оркестрации ресурсов Apache Mesos является, 
framework-структурой, особым типом приложения, предназначенного для исполнения
согласно принципу гранулярного деления~\autocite{impl:mesos}. Такая структура которая состоит из двух компонент:
\begin{enumerate}
    \item планировщика -- компонента управления списка задач и выделения ресурсов для исполнителей этого списка задач;
    \item исполнителей -- набор компонент, непосредственно выполняющих список задач.
\end{enumerate}  

Apache Mesos имеет интеграцию как с Apache Spark, так и с Apache Hadoop и является наиболее удобным
способом запуска и проведения численных экспериментов по прогнозированию взаимодействий пользователей
с рекламными элементами интернет-страниц.
